{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, BatchNormalization, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import relu\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crating the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 65, 318, 3)    0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 65, 318, 3)    12          cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 33, 159, 24)   1824        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 33, 159, 24)   96          convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 17, 80, 36)    21636       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 17, 80, 36)    144         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 9, 40, 48)     43248       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 9, 40, 48)     192         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 9, 40, 64)     27712       batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 9, 40, 64)     256         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 9, 40, 64)     36928       batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 9, 40, 64)     256         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 23040)         0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           2304100     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 100)           400         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 50)            200         dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 10)            40          dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          batchnormalization_9[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 2,442,615\n",
      "Trainable params: 2,441,817\n",
      "Non-trainable params: 798\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x:x/255.0 - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25), (1,1))))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(24,5,5,subsample=(2,2), border_mode='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(36,5,5,subsample=(2,2), border_mode='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(48,5,5,subsample=(2,2), border_mode='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,3,3, border_mode='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,3,3, border_mode='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the dataset with extra collected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "48624/48624 [==============================] - 320s - loss: 0.0483 - val_loss: 0.0145\n",
      "Epoch 2/6\n",
      "48624/48624 [==============================] - 194s - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 3/6\n",
      "48624/48624 [==============================] - 193s - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 4/6\n",
      "48624/48624 [==============================] - 194s - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 5/6\n",
      "48624/48624 [==============================] - 195s - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 6/6\n",
      "48624/48624 [==============================] - 193s - loss: 0.0083 - val_loss: 0.0084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples = []\n",
    "with open('./data2/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "samples=samples[1:]\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "def generator(samples, batch_size=64, path):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        np.random.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            car_images = []\n",
    "            steering_angles = []\n",
    "            for batch_sample in batch_samples: \n",
    "                img_center = (np.asarray(Image.open(path + batch_sample[0].split('\\\\')[-1].split('/')[-1])))\n",
    "                img_left = (np.asarray(Image.open(path + batch_sample[1].split('\\\\')[-1].split('/')[-1])))\n",
    "                img_right = (np.asarray(Image.open(path + batch_sample[2].split('\\\\')[-1].split('/')[-1])))\n",
    "                correction = 0.05\n",
    "                steering_center = float(batch_sample[3])\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "                steering_angles.append(steering_center)\n",
    "                steering_angles.append(steering_left)\n",
    "                steering_angles.append(steering_right)\n",
    "                car_images.append(img_center)\n",
    "                car_images.append(img_left)\n",
    "                car_images.append(img_right)\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(car_images)\n",
    "            y_train = np.array(steering_angles).reshape(len(steering_angles),1)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "train_generator = generator(train_samples, batch_size=64, './data2/IMG/')\n",
    "validation_generator = generator(validation_samples, batch_size=64, './data2/IMG/')\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=\\\n",
    "                    (3*len(train_samples)), validation_data=validation_generator,\\\n",
    "                    nb_val_samples=(3*len(validation_samples)), nb_epoch=6)\n",
    "model.save('model5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model on the primary provide dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "19284/19284 [==============================] - 78s - loss: 0.1504 - val_loss: 0.0215\n",
      "Epoch 2/6\n",
      "19284/19284 [==============================] - 50s - loss: 0.0111 - val_loss: 0.0184\n",
      "Epoch 3/6\n",
      "19284/19284 [==============================] - 50s - loss: 0.0102 - val_loss: 0.0171\n",
      "Epoch 4/6\n",
      "19284/19284 [==============================] - 50s - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 5/6\n",
      "19284/19284 [==============================] - 50s - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 6/6\n",
      "19284/19284 [==============================] - 50s - loss: 0.0095 - val_loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7823941518>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "samples = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "samples=samples[1:]\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=64, './data/IMG/')\n",
    "validation_generator = generator(validation_samples, batch_size=64, './data/IMG/')\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=\\\n",
    "                    (3*len(train_samples)), validation_data=validation_generator,\\\n",
    "                    nb_val_samples=(3*len(validation_samples)), nb_epoch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
